# Awesome-Constraint-Learning [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A list of awesome resources related to constraint learning
## Contents
- [Papers](#papers)
  - [Survey Papers](#survey-papers)
  - [Benchmark](#benchmark)
  - [Data Augmentation](#data-augmentation)
  - [Logical Constraints](#logical-constraints)
  - [Concept bottleneck models](#concept-bottleneck-models)
## Papers
### Survey Papers
| Venue | Title | Affiliation | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Link&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;Source&nbsp;&nbsp; |
| :---: | :---: | :---------: | :---: | :----: |
|IJCAI 2022|Deep Learning with Logical Constraints|University of Oxford| [[paper]](https://arxiv.org/pdf/2205.00523.pdf)![Scholar citations](https://img.shields.io/badge/Citations-39-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)||
|TKDE 2019|Informed machine learning-a taxonomy and survey of integrating prior knowledge into learning systems|Fraunhofer IAIS| [[paper]](https://arxiv.org/pdf/1903.12394.pdf)![Scholar citations](https://img.shields.io/badge/Citations-553-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)||
|Scientific Reports 2022|A review of some techniques for inclusion of domain-knowledge into deep neural networks|| [[paper]](https://www.nature.com/articles/s41598-021-04590-0)![Scholar citations](https://img.shields.io/badge/Citations-97-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)||
### Benchmark
| Venue | Title | Affiliation | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Link&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;Source&nbsp;&nbsp; |
| :---: | :---: | :---------: | :---: | :----: |
|EMNLP 2020|CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning|USC| [[paper]](https://arxiv.org/pdf/1911.03705.pdf)![Scholar citations](https://img.shields.io/badge/Citations-271-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/INK-USC/CommonGen)![GitHub stars](https://img.shields.io/github/stars/INK-USC/CommonGen.svg?logo=github&label=Stars)|
### Data Augmentation
| Venue | Title | Affiliation | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Link&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;Source&nbsp;&nbsp; |
| :---: | :---: | :---------: | :---: | :----: |
|CVPR 2015|Hyper-class Augmented and Regularized Deep Learning for Fine-grained Image Classification|UCSD| [[paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Xie_Hyper-Class_Augmented_and_2015_CVPR_paper.pdf)![Scholar citations](https://img.shields.io/badge/Citations-231-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)||
### Logical Constraints
| Venue | Title | Affiliation | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Link&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;Source&nbsp;&nbsp; |
| :---: | :---: | :---------: | :---: | :----: |
|NIPS 2023|A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints|UCLA| [[paper]](https://arxiv.org/pdf/2312.03905.pdf)![Scholar citations](https://img.shields.io/badge/Citations-0-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/UCLA-StarAI/PseudoSL)![GitHub stars](https://img.shields.io/github/stars/UCLA-StarAI/PseudoSL.svg?logo=github&label=Stars)|
|ACL 2016|Harnessing Deep Neural Networks with Logic Rules|CMU| [[paper]](https://arxiv.org/pdf/1603.06318.pdf)![Scholar citations](https://img.shields.io/badge/Citations-735-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/ZhitingHu/logicnn)![GitHub stars](https://img.shields.io/github/stars/ZhitingHu/logicnn.svg?logo=github&label=Stars)|
|Applied Intelligence 1999|The Connectionist Inductive Learning and Logic Programming System|IC| [[paper]](https://link.springer.com/article/10.1023/A:1008328630915)![Scholar citations](https://img.shields.io/badge/Citations-233-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)||
|ICML 2018|A Semantic Loss Function for Deep Learning with Symbolic Knowledge|UCLA| [[paper]](https://proceedings.mlr.press/v80/xu18h/xu18h.pdf)![Scholar citations](https://img.shields.io/badge/Citations-444-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/UCLA-StarAI/Semantic-Loss)![GitHub stars](https://img.shields.io/github/stars/UCLA-StarAI/Semantic-Loss.svg?logo=github&label=Stars)|
|NAACL 2021|Neurologic decoding:(un) supervised neural text generation with predicate logic constraints|UW| [[paper]](https://arxiv.org/pdf/2010.12884.pdf)![Scholar citations](https://img.shields.io/badge/Citations-98-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/GXimingLu/neurologic_decoding)![GitHub stars](https://img.shields.io/github/stars/GXimingLu/neurologic_decoding.svg?logo=github&label=Stars)|
### Concept bottleneck models
| Venue | Title | Affiliation | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Link&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;Source&nbsp;&nbsp; |
| :---: | :---: | :---------: | :---: | :----: |
|ICML 2020|Concept Bottleneck Models|Standard University| [[paper]](https://arxiv.org/pdf/2007.04612.pdf)![Scholar citations](https://img.shields.io/badge/Citations-492-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/yewsiang/ConceptBottleneck)![GitHub stars](https://img.shields.io/github/stars/yewsiang/ConceptBottleneck.svg?logo=github&label=Stars)|
|ICLR 2023|POST-HOC CONCEPT BOTTLENECK MODELS|Standard University| [[paper]](https://arxiv.org/pdf/2205.15480.pdf)![Scholar citations](https://img.shields.io/badge/Citations-76-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/mertyg/post-hoc-cbm)![GitHub stars](https://img.shields.io/github/stars/mertyg/post-hoc-cbm.svg?logo=github&label=Stars)|
|ICML 2023|Dividing and Conquering a BlackBox to a Mixture of Interpretable Models: Route, Interpret, Repeat|BU| [[paper]](https://arxiv.org/pdf/2307.05350.pdf)![Scholar citations](https://img.shields.io/badge/Citations-3-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/batmanlab/ICML-2023-Route-interpret-repeat)![GitHub stars](https://img.shields.io/github/stars/batmanlab/ICML-2023-Route-interpret-repeat.svg?logo=github&label=Stars)|
|CVPR 2023|Language in a Bottle: Language Model Guided Concept Bottlenecks for Interpretable Image Classification|UPENN| [[paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Language_in_a_Bottle_Language_Model_Guided_Concept_Bottlenecks_for_CVPR_2023_paper.pdf)![Scholar citations](https://img.shields.io/badge/Citations-46-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/YueYANG1996/LaBo)![GitHub stars](https://img.shields.io/github/stars/YueYANG1996/LaBo.svg?logo=github&label=Stars)|
|ICLR 2023|Label-free Concept Bottleneck Models|UCSD| [[paper]](https://openreview.net/pdf?id=FlCg47MNvBA)![Scholar citations](https://img.shields.io/badge/Citations-8-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/Trustworthy-ML-Lab/Label-free-CBM)![GitHub stars](https://img.shields.io/github/stars/Trustworthy-ML-Lab/Label-free-CBM.svg?logo=github&label=Stars)|
|AAAI 2023|Interactive Concept Bottleneck Models|Google| [[paper]](https://arxiv.org/pdf/2212.07430.pdf)![Scholar citations](https://img.shields.io/badge/Citations-19-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/google-research/google-research/tree/master/interactive_cbms)|
|NIPS 2022|Addressing Leakage in Concept Bottleneck Models|Harvard University| [[paper]](https://finale.seas.harvard.edu/sites/scholar.harvard.edu/files/finale/files/10494_addressing_leakage_in_concept_.pdf)![Scholar citations](https://img.shields.io/badge/Citations-22-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/dtak/addressing-leakage)![GitHub stars](https://img.shields.io/github/stars/dtak/addressing-leakage.svg?logo=github&label=Stars)|
|ICML 2021|Promises and Pitfalls of Black-Box Concept Learning Models|Harvard University| [[paper]](https://arxiv.org/pdf/2106.13314.pdf)![Scholar citations](https://img.shields.io/badge/Citations-51-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)||
|NIPS 2021|Editing a classifier by rewriting its prediction rules|MIT| [[paper]](https://proceedings.neurips.cc/paper/2021/file/c46489a2d5a9a9ecfc53b17610926ddd-Paper.pdf)![Scholar citations](https://img.shields.io/badge/Citations-55-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/MadryLab/EditingClassifiers)![GitHub stars](https://img.shields.io/github/stars/MadryLab/EditingClassifiers.svg?logo=github&label=Stars)|
|ICML 2018|Interpretability Beyond Feature Attribution:Quantitative Testing with Concept Activation Vectors (TCAV)|Google| [[paper]](https://arxiv.org/pdf/1711.11279.pdf)![Scholar citations](https://img.shields.io/badge/Citations-0-_.svg?logo=google-scholar&labelColor=4f4f4f&color=3388ee)| [[code]](https://github.com/tensorflow/tcav)![GitHub stars](https://img.shields.io/github/stars/tensorflow/tcav.svg?logo=github&label=Stars)|
